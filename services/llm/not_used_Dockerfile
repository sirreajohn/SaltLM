FROM debian:bookworm

RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Clone llama.cpp
RUN git clone https://github.com/ggml-org/llama.cpp.git

WORKDIR /app/llama.cpp

# Create build directory
RUN cmake -B build -S . \
    -DLLAMA_BUILD_SERVER=ON \
    -DGGML_NATIVE=OFF

# Build
RUN cmake --build build --config Release -j$(nproc)

EXPOSE 8080

CMD ["./build/bin/server", "-m", "/models/model.gguf", "--host", "0.0.0.0", "--port", "8080"]